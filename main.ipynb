{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBDW2csUF7eI"
      },
      "outputs": [],
      "source": [
        "# need to restart notebook in order to get numpy 1.x.x after installing it ...\n",
        "!pip install numpy==1.26.4\n",
        "import numpy as np\n",
        "if int(np.__version__[0]) > 1:\n",
        "  import os\n",
        "  os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtjyGFrGn5vS"
      },
      "outputs": [],
      "source": [
        "!pip install timesfm\n",
        "!pip install sktime\n",
        "!pip install chronos-forecasting\n",
        "!pip install tqdm_joblib\n",
        "!pip install u8darts==0.34.0\n",
        "!pip install statsforecast\n",
        "!pip install pytorch_lightning\n",
        "!pip install pytorch-forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8HUaOSInRS_"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sktime.datasets import load_tsf_to_dataframe, load_forecastingdata, load_fpp3\n",
        "from sktime.split import ExpandingSlidingWindowSplitter, ExpandingWindowSplitter, TemporalTrainTestSplitter\n",
        "from sktime.transformations.series.difference import Differencer\n",
        "from sktime.forecasting.statsforecast import StatsForecastAutoARIMA\n",
        "from sktime.forecasting.naive import NaiveForecaster\n",
        "from sktime.forecasting.pytorchforecasting import PytorchForecastingNBeats\n",
        "from sktime.forecasting.darts import DartsXGBModel\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import torch\n",
        "import timesfm\n",
        "from chronos import BaseChronosPipeline\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm_joblib import tqdm_joblib\n",
        "import warnings\n",
        "import time\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "067T5JW8mfX4"
      },
      "outputs": [],
      "source": [
        "class EvalMode(Enum):\n",
        "  TRAIN_TEST_SPLIT = 0\n",
        "  EXPANDING_WINDOW = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nnrU8EWiCLFq"
      },
      "outputs": [],
      "source": [
        "class ModelType(Enum):\n",
        "  TimesFM = 0\n",
        "  TimesFM2 = 1\n",
        "  Chronos = 2\n",
        "  AutoARIMA = 3\n",
        "  XGBoost = 4\n",
        "  Baseline = 5\n",
        "  NBeats = 6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pad_dims_fn = lambda eval_mode, maxlen, x : (maxlen - len(x), 0) if eval_mode == EvalMode.TRAIN_TEST_SPLIT else (0, maxlen - len(x))"
      ],
      "metadata": {
        "id": "04i82EYo4JeX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V6DTCt2HlhOr"
      },
      "outputs": [],
      "source": [
        "ds_cache = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AHMek3exAyjB"
      },
      "outputs": [],
      "source": [
        "def load_monash_dataset(name):\n",
        "  if name in ds_cache:\n",
        "    df, metadata = ds_cache[name]\n",
        "    return df.copy(), metadata\n",
        "  df, metadata = load_forecastingdata(name)\n",
        "  ds_cache[name] = (df, metadata)\n",
        "  return df.copy(), metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wOTRzU5Cmp0x"
      },
      "outputs": [],
      "source": [
        "def df_to_ndarray(df, horizon_length, initial_context_length, pad_dims_fn, eval_mode, value_column='series_value', length_column='series_length'):\n",
        "  max_series_length = max(df[length_column])\n",
        "  # if using single train test split, we don't have initial context, just pad to max length\n",
        "  padded_length = max_series_length if eval_mode == EvalMode.TRAIN_TEST_SPLIT else math.ceil((max_series_length - initial_context_length) / horizon_length) * horizon_length + initial_context_length\n",
        "  df[value_column] = df[value_column].apply(lambda x: np.pad(x, pad_dims_fn(eval_mode, padded_length, x), constant_values=0))\n",
        "  return np.vstack(df[value_column])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-RSRHoAu03XW"
      },
      "outputs": [],
      "source": [
        "def init_monash_dataset(name, horizon_length, initial_context_length, pad_dims_fn, eval_mode=EvalMode.TRAIN_TEST_SPLIT, plot=False, max_series_length = None, max_length = None):\n",
        "  df, metadata = load_monash_dataset(name)\n",
        "  if(max_length is not None):\n",
        "    df = df.head(max_length)\n",
        "\n",
        "  if max_series_length is not None:\n",
        "    df['series_value'] = df['series_value'].apply(lambda x: x[:max_series_length])\n",
        "\n",
        "  df['series_length'] = df['series_value'].apply(lambda x: len(x))\n",
        "\n",
        "  if plot:\n",
        "    plt.hist(df['series_length'])\n",
        "    plt.xlabel('Series Length')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "  dataset = df_to_ndarray(df, horizon_length, initial_context_length, pad_dims_fn, eval_mode)\n",
        "  print(name + \", shape: \" + str(dataset.shape))\n",
        "  print(\"Metadata:\", metadata)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_etth(horizon_length, initial_context_length, pad_dims_fn, eval_mode=EvalMode.TRAIN_TEST_SPLIT, max_series_length=None):\n",
        "  df1 = pd.read_csv('https://raw.githubusercontent.com/zhouhaoyi/ETDataset/refs/heads/main/ETT-small/ETTh1.csv')\n",
        "  df2 = pd.read_csv('https://raw.githubusercontent.com/zhouhaoyi/ETDataset/refs/heads/main/ETT-small/ETTh2.csv')\n",
        "  df = pd.DataFrame({'series_value': [df1['OT'].tolist(), df2['OT'].tolist()] })\n",
        "  if max_series_length is not None:\n",
        "    df['series_value'] = df['series_value'].apply(lambda x: x[:max_series_length])\n",
        "\n",
        "  df['series_length'] = df['series_value'].apply(lambda x: len(x))\n",
        "\n",
        "  dataset = df_to_ndarray(df, horizon_length, initial_context_length, pad_dims_fn, eval_mode)\n",
        "  print(\"ETTh, shape: \" + str(dataset.shape))\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "puYGWOmzuXyA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RErUbH66mhSV"
      },
      "outputs": [],
      "source": [
        "def get_timesfm_model(horizon_length, v1=True):\n",
        "  if v1:\n",
        "    return timesfm.TimesFm(\n",
        "        hparams=timesfm.TimesFmHparams(\n",
        "          backend=\"gpu\",\n",
        "          per_core_batch_size=32,\n",
        "          horizon_len=horizon_length,\n",
        "        ),\n",
        "        checkpoint=timesfm.TimesFmCheckpoint(\n",
        "          huggingface_repo_id=\"google/timesfm-1.0-200m-pytorch\"),\n",
        "    )\n",
        "  else:\n",
        "    return timesfm.TimesFm(\n",
        "        hparams=timesfm.TimesFmHparams(\n",
        "            backend=\"gpu\",\n",
        "            per_core_batch_size=32,\n",
        "            horizon_len=horizon_length,\n",
        "            num_layers=50,\n",
        "            use_positional_embedding=False,\n",
        "            context_len=2048,\n",
        "        ),\n",
        "        checkpoint=timesfm.TimesFmCheckpoint(\n",
        "            huggingface_repo_id=\"google/timesfm-2.0-500m-pytorch\"),\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xKuu78fmMAIs"
      },
      "outputs": [],
      "source": [
        "def get_chronos_model(name='amazon/chronos-bolt-base'):\n",
        "  return BaseChronosPipeline.from_pretrained(\n",
        "    name,\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nbeats_model(horizon_length):\n",
        "  return PytorchForecastingNBeats(\n",
        "    trainer_params={\n",
        "        \"max_epochs\": 1\n",
        "    },\n",
        "    #recommended params for generic mode\n",
        "    model_params={\n",
        "        \"prediction_length\": horizon_length,\n",
        "        \"stack_types\": [\"generic\"],\n",
        "        \"num_blocks\": [1],\n",
        "        \"num_block_layers\": [4],\n",
        "        \"widths\": [512],\n",
        "        \"sharing\": False,\n",
        "        \"expansion_coefficient_lengths\": [32]}\n",
        "    )"
      ],
      "metadata": {
        "id": "N03N6FYRiTVQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "x7LInweuMO18"
      },
      "outputs": [],
      "source": [
        "def get_timesfm_predict_fn(horizon_length, frequency, v1=True):\n",
        "  model = get_timesfm_model(horizon_length, v1)\n",
        "  def _predict(context):\n",
        "    point_forecast, experimental_quantile_forecast = model.forecast(\n",
        "        context,\n",
        "        freq=np.repeat(frequency, len(context)))\n",
        "    return point_forecast\n",
        "  return _predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "c44b--kqR8TB"
      },
      "outputs": [],
      "source": [
        "def get_chronos_predict_fn(horizon_length, model_name='amazon/chronos-bolt-base'):\n",
        "  model = get_chronos_model(model_name)\n",
        "  def _predict(context):\n",
        "    quantiles, mean = model.predict_quantiles(\n",
        "        context=torch.from_numpy(context),\n",
        "        prediction_length=horizon_length,\n",
        "        quantile_levels=[0.5]\n",
        "    )\n",
        "    return quantiles[:, :, 0].numpy()\n",
        "  return _predict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_xgb_predict_fn(horizon_length, max_lags):\n",
        "  def _predict(context):\n",
        "    lags = max_lags if max_lags < (context.shape[1]-1) else (context.shape[1]-1)\n",
        "    model = DartsXGBModel(lags=lags)\n",
        "    forecast = model.fit_predict(np.expand_dims(context, axis=1), fh=np.arange(1, horizon_length + 1))\n",
        "    return forecast[:, 0, :]\n",
        "  return _predict"
      ],
      "metadata": {
        "id": "bA7pjZaElubp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_EIjM-xsWC_s"
      },
      "outputs": [],
      "source": [
        "def get_sktime_forecaster_parallel_predict_fn(model, horizon_length):\n",
        "  def _predict(context):\n",
        "    def _fit_predict(y):\n",
        "      model.reset()\n",
        "      return model.fit_predict(y, fh=np.arange(1, horizon_length + 1))\n",
        "\n",
        "    delayedFunc = delayed(_fit_predict)\n",
        "    with tqdm_joblib(tqdm(desc=\"Processing\", total=context.shape[0])):\n",
        "      forecast = Parallel(n_jobs=-1, verbose=10)(delayedFunc(context[i, :]) for i in range(context.shape[0]))\n",
        "    return np.array(forecast).squeeze(axis=2)\n",
        "  return _predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QWm00PHldQbg"
      },
      "outputs": [],
      "source": [
        "def get_sktime_forecaster_predict_fn(model, horizon_length):\n",
        "  def _predict(context):\n",
        "    model.reset()\n",
        "    forecast = model.fit_predict(np.expand_dims(context, axis=1), fh=np.arange(1, horizon_length + 1))\n",
        "    return forecast[:, 0, :]\n",
        "  return _predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LEI3CG4rMzGp"
      },
      "outputs": [],
      "source": [
        "# If pre-padding is used this returns only True which is fine when calculating the errors, as there is no padding in the forecasted horizon we need to exclude\n",
        "def get_post_padding_mask(values, padding_value=0):\n",
        "    last_non_zero_indices = np.max((values != 0) * np.arange(values.shape[1]), axis=1)\n",
        "    col_indices = np.arange(values.shape[1])\n",
        "    return col_indices[None, :] <= last_non_zero_indices[:, None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Cj4mFdV003XX"
      },
      "outputs": [],
      "source": [
        "def rmse_with_padding(predictions, truth, padding_value=0):\n",
        "  weights = get_post_padding_mask(truth, padding_value).astype(float)\n",
        "  weighted_squared_errors = weights * ((predictions - truth) ** 2)\n",
        "  return np.sqrt(np.sum(weighted_squared_errors) / np.sum(weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Qp3M0nDu8rJ6"
      },
      "outputs": [],
      "source": [
        "def mae_with_padding(predictions, truth, padding_value=0):\n",
        "  mask = get_post_padding_mask(truth, padding_value)\n",
        "  absolute_errors = np.abs(truth - predictions)\n",
        "  masked_absolute_errors = absolute_errors[mask]\n",
        "  return np.mean(masked_absolute_errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EfvSJfWCdvrV"
      },
      "outputs": [],
      "source": [
        "def weighted_mape_with_padding(predictions, truth, padding_value=0):\n",
        "  mask = get_post_padding_mask(truth, padding_value)\n",
        "  numerator = np.sum(np.abs(truth - predictions)[mask])\n",
        "  denominator = np.sum(truth[mask])\n",
        "\n",
        "  if denominator == 0:\n",
        "        return np.nan\n",
        "  return (numerator / denominator) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bxHqEwND7rSl"
      },
      "outputs": [],
      "source": [
        "def calc_metrics(actual, predictions):\n",
        "  mae = mae_with_padding(predictions, actual)\n",
        "  wmape = weighted_mape_with_padding(predictions, actual)\n",
        "  rmse = rmse_with_padding(predictions, actual)\n",
        "  return { 'mae': mae, 'wmape': wmape, 'rmse': rmse }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tC2q4GxcQtOe"
      },
      "outputs": [],
      "source": [
        "def predict(dataset, predict_fn, splits_indices, horizon_length):\n",
        "  predictions = np.empty(shape=(len(dataset), 0))\n",
        "  partial_metrics = []\n",
        "  for context_idx, horizon_idx in splits_indices:\n",
        "    context = dataset[:, context_idx]\n",
        "    horizon = dataset[:, horizon_idx]\n",
        "    forecast = predict_fn(context)\n",
        "\n",
        "    partial_metrics.append(calc_metrics(horizon, forecast))\n",
        "    predictions = np.append(predictions, forecast, axis=1)\n",
        "  return predictions, partial_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8VxgFwSD7GEI"
      },
      "outputs": [],
      "source": [
        "def infer(dataset, splitter, predict_fn, horizon_length, context_length):\n",
        "  splits = list(splitter.split(dataset[0]))\n",
        "\n",
        "  start_time = time.time()\n",
        "  predictions, partial_metrics = predict(dataset, predict_fn, splits, horizon_length)\n",
        "  elapsed_time = str(round(time.time() - start_time, 1))\n",
        "  metrics = calc_metrics(dataset[:, context_length:], predictions)\n",
        "  return { 'predictions': predictions, 'metrics': metrics, 'partial_metrics': partial_metrics, 'time': elapsed_time }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HDap72-Ndw3N"
      },
      "outputs": [],
      "source": [
        "def get_ds_splitter(horizon_length, eval_mode=EvalMode.TRAIN_TEST_SPLIT, initial_context_length=0):\n",
        "  return TemporalTrainTestSplitter(test_size=horizon_length) if eval_mode == EvalMode.TRAIN_TEST_SPLIT \\\n",
        "    else ExpandingWindowSplitter(fh=np.arange(1, horizon_length + 1), step_length=horizon_length, initial_window=initial_context_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vPFuX00kMLkj"
      },
      "outputs": [],
      "source": [
        "def infer_on_dataset(dataset, eval_mode, horizon_length, models, context_length=0, timesfm_freq=0, seasonal_period=1, xgb_lags=1):\n",
        "  splitter = get_ds_splitter(horizon_length, eval_mode, context_length)\n",
        "\n",
        "  model_to_infer_fn = {\n",
        "      ModelType.TimesFM: lambda: get_timesfm_predict_fn(horizon_length, frequency=timesfm_freq, v1=True),\n",
        "      ModelType.TimesFM2: lambda: get_timesfm_predict_fn(horizon_length, frequency=timesfm_freq, v1=False),\n",
        "      ModelType.Chronos: lambda: get_chronos_predict_fn(horizon_length),\n",
        "      ModelType.AutoARIMA: lambda: get_sktime_forecaster_parallel_predict_fn(StatsForecastAutoARIMA(sp=seasonal_period), horizon_length), # Using the parallel approach for every TS gives faster inference time for AutoARIMA.\n",
        "      ModelType.XGBoost: lambda: get_xgb_predict_fn(horizon_length, max_lags=xgb_lags),\n",
        "      ModelType.NBeats: lambda: get_sktime_forecaster_predict_fn(get_nbeats_model(horizon_length), horizon_length),\n",
        "      ModelType.Baseline: lambda: get_sktime_forecaster_predict_fn(NaiveForecaster(sp=seasonal_period), horizon_length)\n",
        "  }\n",
        "\n",
        "  model_infer_fns = []\n",
        "  for model in models:\n",
        "    model_infer_fns.append((model.name, model_to_infer_fn[model]()))\n",
        "\n",
        "  results = {}\n",
        "  for model_name, predict_fn in model_infer_fns:\n",
        "    print(\"Infer using \" + model_name + \"...\")\n",
        "    with warnings.catch_warnings():\n",
        "      warnings.filterwarnings(\"ignore\")\n",
        "      results[model_name] = infer(dataset, splitter, predict_fn, horizon_length, context_length)\n",
        "\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3-_WkN-E8LhS"
      },
      "outputs": [],
      "source": [
        "def plot_series(dataset, predictions, context_length, horizon_length, series_indices, cols=3, row_size=3, plotted_context_length=0):\n",
        "  rows = math.ceil(len(series_indices) / cols)\n",
        "  fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
        "\n",
        "  # Ensure axes is always 2D\n",
        "  if cols == 1:\n",
        "    axes = np.atleast_2d(axes).T  # Convert to column vector\n",
        "  if rows == 1:\n",
        "    axes = np.atleast_2d(axes)  # Convert to row vector\n",
        "\n",
        "\n",
        "  for i in range(0, rows):\n",
        "    for j in range(0, cols):\n",
        "      idx = i * cols + j\n",
        "      if idx >= len(series_indices):\n",
        "        axes[i, j].axis('off')\n",
        "        continue\n",
        "\n",
        "      series_idx = series_indices[idx]\n",
        "      truth = dataset[series_idx][context_length:]\n",
        "\n",
        "      padding_mask = get_post_padding_mask(truth.reshape(1, -1)) # Only Trues for pre-padding (expanding window eval) so no side-effects if train-test split.\n",
        "      non_padded_values_idx = np.nonzero(padding_mask[0])[0]\n",
        "      plotted_truth = truth[non_padded_values_idx]\n",
        "\n",
        "      if plotted_context_length > 0:\n",
        "          initial_ctx = dataset[series_idx][context_length-plotted_context_length:context_length]\n",
        "          # When using pre-padding (train-test eval) we need to trim the leading zeros if any.\n",
        "          initial_ctx = initial_ctx[np.argmax(initial_ctx != 0):]\n",
        "          plotted_context_length = len(initial_ctx)\n",
        "          plotted_truth = np.concatenate((initial_ctx, truth[non_padded_values_idx])) # get the initial ctx as well\n",
        "\n",
        "      axes[i, j].plot(plotted_truth, label=\"Actual\")\n",
        "\n",
        "      for name, model_predictions in predictions.items():\n",
        "        if name == 'Baseline':\n",
        "          continue\n",
        "\n",
        "        prediction = model_predictions[series_idx]\n",
        "        plotted_prediction = np.pad(prediction[non_padded_values_idx], (plotted_context_length, 0), constant_values=np.nan) # pad the initial ctx\n",
        "        axes[i, j].plot(plotted_prediction, label=name, alpha=0.7)\n",
        "\n",
        "      # Vertical lines for horizons\n",
        "      ymin, ymax = axes[i, j].get_ylim()\n",
        "      axes[i, j].vlines(x=np.arange(start=context_length, step=horizon_length, stop=len(plotted_truth)), ymin=ymin, ymax=ymax, colors='lightblue', ls='--', alpha=0.7)\n",
        "\n",
        "      axes[i, j].set_title(\"Series \" + str(series_idx + 1))\n",
        "      axes[i, j].legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "kfqEXKLIcTOJ"
      },
      "outputs": [],
      "source": [
        "def run(experiments):\n",
        "  results = {}\n",
        "  for name, experiment in experiments.items():\n",
        "    print(\"Running experiment '{}'..\".format(name))\n",
        "    dataset = experiment['dataset_init_fn'](experiment['eval_mode'], experiment['horizon_length'], experiment['initial_context_length'])\n",
        "\n",
        "    context_length = len(dataset[0]) - experiment['horizon_length'] if experiment['eval_mode'] == EvalMode.TRAIN_TEST_SPLIT else experiment['initial_context_length']\n",
        "\n",
        "    result = infer_on_dataset(dataset,\n",
        "                              experiment['eval_mode'],\n",
        "                              experiment['horizon_length'],\n",
        "                              experiment['models'],\n",
        "                              context_length,\n",
        "                              experiment['timesfm_freq'],\n",
        "                              experiment['seasonal_period'],\n",
        "                              experiment.get('xgb_lags', experiment['seasonal_period']))\n",
        "\n",
        "    results[name] = {'dataset': dataset, 'context_length': context_length, 'model_results': result}\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pT1o5Bsy7akm"
      },
      "outputs": [],
      "source": [
        "def plot_partial_metrics(model_results):\n",
        "  for model_name, model_result in model_results.items():\n",
        "    partial_metrics = model_result['partial_metrics']\n",
        "    df = pd.DataFrame(partial_metrics)\n",
        "    df.plot(subplots=True, layout=(3, 1), figsize=(8, 6), marker='o', title=f'Error terms per fold for {model_name}', sharex=False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_V1FmN4XjNYP"
      },
      "outputs": [],
      "source": [
        "def plot_experiment_result(exp_name, exp_result, exp_config):\n",
        "  print(\"Experiment '{}'\".format(exp_name))\n",
        "  predictions = {}\n",
        "\n",
        "  baseline = exp_result['model_results']['Baseline']\n",
        "\n",
        "  for model_name, model_result in exp_result['model_results'].items():\n",
        "\n",
        "    predictions[model_name] = model_result['predictions']\n",
        "    print(model_name + \":\")\n",
        "    print(\"MAE: \", model_result['metrics']['mae'])\n",
        "    print(\"RMSE: \", model_result['metrics']['rmse'])\n",
        "    print(\"MASE: \", model_result['metrics']['mae'] / baseline['metrics']['mae'])\n",
        "    print(\"wMAPE: \", model_result['metrics']['wmape'])\n",
        "    print(\"Time: \", model_result['time'])\n",
        "    print(\"\\n\")\n",
        "\n",
        "  plot_config = exp_config.get('plot_config')\n",
        "  if plot_config is not None and plot_config.get('plot', True):\n",
        "    plot_series(\n",
        "        dataset=exp_result['dataset'],\n",
        "        predictions=predictions,\n",
        "        context_length=exp_result['context_length'],\n",
        "        horizon_length=exp_config['horizon_length'],\n",
        "        series_indices=plot_config['series_indices'],\n",
        "        cols=plot_config.get('cols', 3),\n",
        "        plotted_context_length=plot_config.get('plotted_context_length', exp_result['context_length']))\n",
        "\n",
        "  if plot_config is not None and plot_config.get('plot_partial_metrics', False):\n",
        "    plot_partial_metrics(exp_result['model_results'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "experiments = {\n",
        "    'us_births_dataset_tts_30': {\n",
        "        'eval_mode': EvalMode.TRAIN_TEST_SPLIT,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "        ],\n",
        "        'horizon_length': 30,\n",
        "        'initial_context_length': 0, # Ignored for train-test split\n",
        "        'timesfm_freq': 0,\n",
        "        'seasonal_period': 7,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"us_births_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em, max_length=4096),\n",
        "        'plot_config': {\n",
        "            'plot': True,\n",
        "            'plot_partial_metrics': False,\n",
        "            'series_indices': [0],\n",
        "            'cols': 1,\n",
        "            'plotted_context_length': 256\n",
        "        }\n",
        "    },\n",
        "    'us_births_dataset_ew_30': {\n",
        "        'eval_mode': EvalMode.EXPANDING_WINDOW,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "        ],\n",
        "        'horizon_length': 30,\n",
        "        'initial_context_length': 2048, # Ignored for train-test split\n",
        "        'timesfm_freq': 0,\n",
        "        'xgb_lags': 2048,\n",
        "        'seasonal_period': 7,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"us_births_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em, max_length=4096),\n",
        "        'plot_config': {\n",
        "            'plot_partial_metrics': False,\n",
        "            'plot': False,\n",
        "            'series_indices': [0],\n",
        "            'cols': 1,\n",
        "            'plotted_context_length': 256\n",
        "        }\n",
        "    },\n",
        "    'us_births_dataset_tts_365': {\n",
        "        'eval_mode': EvalMode.TRAIN_TEST_SPLIT,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "        ],\n",
        "        'horizon_length': 365,\n",
        "        'initial_context_length': 0, # Ignored for train-test split\n",
        "        'timesfm_freq': 0,\n",
        "        'seasonal_period': 7,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"us_births_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em, max_length=4096),\n",
        "        'plot_config': {\n",
        "            'plot': True,\n",
        "            'plot_partial_metrics': False,\n",
        "            'series_indices': [0],\n",
        "            'cols': 1,\n",
        "            'plotted_context_length': 256\n",
        "        }\n",
        "    },\n",
        "    'us_births_dataset_ew_365': {\n",
        "        'eval_mode': EvalMode.EXPANDING_WINDOW,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "        ],\n",
        "        'horizon_length': 365,\n",
        "        'initial_context_length': 2048, # Ignored for train-test split\n",
        "        'timesfm_freq': 0,\n",
        "        'xgb_lags': 2048,\n",
        "        'seasonal_period': 7,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"us_births_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em, max_length=4096),\n",
        "        'plot_config': {\n",
        "            'plot_partial_metrics': False,\n",
        "            'plot': False,\n",
        "            'series_indices': [0],\n",
        "            'cols': 1,\n",
        "            'plotted_context_length': 256\n",
        "        }\n",
        "    },\n",
        "    'fred_md_dataset_tts_12': {\n",
        "        'eval_mode': EvalMode.TRAIN_TEST_SPLIT,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 12,\n",
        "        'initial_context_length': 0, # Ignored for train-test split\n",
        "        'timesfm_freq': 1,\n",
        "        'seasonal_period': 1,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"fred_md_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em),\n",
        "        'plot_config': {\n",
        "            'plot': False,\n",
        "            'plot_partial_metrics': False,\n",
        "            'series_indices': np.arange(107),\n",
        "            'cols': 2\n",
        "        }\n",
        "    },\n",
        "    'fred_md_dataset_ew_12': {\n",
        "        'eval_mode': EvalMode.EXPANDING_WINDOW,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 12,\n",
        "        'initial_context_length': 256,\n",
        "        'timesfm_freq': 1,\n",
        "        'seasonal_period': 1,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"fred_md_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em),\n",
        "        'plot_config': {\n",
        "            'plot_partial_metrics': False,\n",
        "            'plot': False,\n",
        "            'series_indices': np.arange(107),\n",
        "            'cols': 2\n",
        "        }\n",
        "    },\n",
        "    'fred_md_dataset_tts_60': {\n",
        "        'eval_mode': EvalMode.TRAIN_TEST_SPLIT,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 60,\n",
        "        'initial_context_length': 0, # Ignored for train-test split\n",
        "        'timesfm_freq': 1,\n",
        "        'seasonal_period': 1,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"fred_md_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em),\n",
        "        'plot_config': {\n",
        "            'plot': True,\n",
        "            'plot_partial_metrics': False,\n",
        "            'series_indices': np.arange(107),\n",
        "            'plotted_context_length': 120,\n",
        "            'cols': 2\n",
        "        }\n",
        "    },\n",
        "    'fred_md_dataset_ew_60': {\n",
        "        'eval_mode': EvalMode.EXPANDING_WINDOW,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 60,\n",
        "        'initial_context_length': 256,\n",
        "        'timesfm_freq': 1,\n",
        "        'seasonal_period': 1,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"fred_md_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em),\n",
        "        'plot_config': {\n",
        "            'plot_partial_metrics': False,\n",
        "            'plot': True,\n",
        "            'series_indices': np.arange(107),\n",
        "            'cols': 2\n",
        "        }\n",
        "    },\n",
        "    'etth1_tts_96': {\n",
        "        'eval_mode': EvalMode.TRAIN_TEST_SPLIT,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 96,\n",
        "        'initial_context_length': 0, # Ignored for train-test split\n",
        "        'timesfm_freq': 0,\n",
        "        'seasonal_period': 24,\n",
        "        'xgb_lags': 24,\n",
        "        'dataset_init_fn': lambda em, hl, icl: load_etth(horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em, max_series_length=4096),\n",
        "        'plot_config': {\n",
        "            'plot': True,\n",
        "            'plot_partial_metrics': False,\n",
        "            'series_indices': np.arange(2),\n",
        "            'plotted_context_length': 192,\n",
        "            'cols': 1\n",
        "        }\n",
        "    },\n",
        "    'etth1_ew_96': {\n",
        "        'eval_mode': EvalMode.EXPANDING_WINDOW,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 96,\n",
        "        'initial_context_length': 2048, # Ignored for train-test split\n",
        "        'timesfm_freq': 0,\n",
        "        'seasonal_period': 24,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: load_etth(horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em, max_series_length=4096),\n",
        "        'plot_config': {\n",
        "            'plot': False,\n",
        "            'plot_partial_metrics': False,\n",
        "            'series_indices': np.arange(2),\n",
        "            'plotted_context_length': 120,\n",
        "            'cols': 1\n",
        "        }\n",
        "    },\n",
        "    'etth1_tts_192': {\n",
        "        'eval_mode': EvalMode.TRAIN_TEST_SPLIT,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 192,\n",
        "        'initial_context_length': 0, # Ignored for train-test split\n",
        "        'timesfm_freq': 0,\n",
        "        'seasonal_period': 24,\n",
        "        'xgb_lags': 24,\n",
        "        'dataset_init_fn': lambda em, hl, icl: load_etth(horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em, max_series_length=4096),\n",
        "        'plot_config': {\n",
        "            'plot': True,\n",
        "            'plot_partial_metrics': False,\n",
        "            'series_indices': np.arange(2),\n",
        "            'plotted_context_length': 480,\n",
        "            'cols': 1\n",
        "        }\n",
        "    },\n",
        "    'etth1_ew_192': {\n",
        "        'eval_mode': EvalMode.EXPANDING_WINDOW,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 192,\n",
        "        'initial_context_length': 2048, # Ignored for train-test split\n",
        "        'timesfm_freq': 0,\n",
        "        'seasonal_period': 24,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: load_etth(horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em, max_series_length=4096),\n",
        "        'plot_config': {\n",
        "            'plot': False,\n",
        "            'plot_partial_metrics': False,\n",
        "            'series_indices': np.arange(2),\n",
        "            'plotted_context_length': 120,\n",
        "            'cols': 1\n",
        "        }\n",
        "    },\n",
        "    'covid_deaths_dataset_tts_7': {\n",
        "        'eval_mode': EvalMode.TRAIN_TEST_SPLIT,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 7,\n",
        "        'initial_context_length': 0,\n",
        "        'timesfm_freq': 0,\n",
        "        'seasonal_period': 1,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"covid_deaths_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em),\n",
        "        'plot_config': {\n",
        "            'plot_partial_metrics': False,\n",
        "            'plot': True,\n",
        "            'series_indices': np.arange(20),\n",
        "            'cols': 2\n",
        "        }\n",
        "    },\n",
        "    'covid_deaths_dataset_ew_7': {\n",
        "        'eval_mode': EvalMode.EXPANDING_WINDOW,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 7,\n",
        "        'initial_context_length': 96,\n",
        "        'timesfm_freq': 0,\n",
        "        'seasonal_period': 1,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"covid_deaths_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em),\n",
        "        'plot_config': {\n",
        "            'plot_partial_metrics': False,\n",
        "            'plot': False,\n",
        "            'series_indices': np.arange(200),\n",
        "            'cols': 2\n",
        "        }\n",
        "    },\n",
        "    'covid_deaths_dataset_tts_30': {\n",
        "        'eval_mode': EvalMode.TRAIN_TEST_SPLIT,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 30,\n",
        "        'initial_context_length': 0,\n",
        "        'timesfm_freq': 0,\n",
        "        'seasonal_period': 1,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"covid_deaths_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em),\n",
        "        'plot_config': {\n",
        "            'plot_partial_metrics': False,\n",
        "            'plot': True,\n",
        "            'series_indices': np.arange(20),\n",
        "            'cols': 2\n",
        "        }\n",
        "    },\n",
        "    'covid_deaths_dataset_ew_30': {\n",
        "        'eval_mode': EvalMode.EXPANDING_WINDOW,\n",
        "        'models': [\n",
        "            ModelType.TimesFM,\n",
        "            ModelType.TimesFM2,\n",
        "            ModelType.Chronos,\n",
        "            ModelType.AutoARIMA,\n",
        "            ModelType.XGBoost,\n",
        "            ModelType.NBeats,\n",
        "            ModelType.Baseline\n",
        "          ],\n",
        "        'horizon_length': 30,\n",
        "        'initial_context_length': 96,\n",
        "        'timesfm_freq': 0,\n",
        "        'seasonal_period': 1,\n",
        "        'xgb_lags': 2048,\n",
        "        'dataset_init_fn': lambda em, hl, icl: init_monash_dataset(\"covid_deaths_dataset\", horizon_length=hl, initial_context_length=icl, pad_dims_fn=pad_dims_fn, eval_mode=em),\n",
        "        'plot_config': {\n",
        "            'plot_partial_metrics': False,\n",
        "            'plot': False,\n",
        "            'series_indices': np.arange(212),\n",
        "            'cols': 2\n",
        "        }\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "00GA0YMS734y"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger(\"darts\").setLevel(logging.ERROR)\n",
        "\n",
        "r = run(experiments)\n",
        "for exp_name, exp_result in r.items():\n",
        "  plot_experiment_result(exp_name, exp_result, experiments[exp_name])"
      ],
      "metadata": {
        "id": "ETH3gm9NXD5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzcHbn_ZLeUp"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30887,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}